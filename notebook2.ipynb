{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df795e88",
   "metadata": {},
   "source": [
    "# Uncovering Latent Market Structure in BTC <br> with Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21d528ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c94e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download OHLCV minutely BTC 2023 data\n",
    "df = pd.read_csv('./df_btc.csv', index_col=0).dropna()\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df = df.loc[:'2023-05-31 23:59:00',:]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbaa8191",
   "metadata": {},
   "source": [
    "# Features Builder Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144237da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureBuilder:\n",
    "\n",
    "    def __init__(self, df, config):\n",
    "        \"\"\"Fetch dataframe and config, extract columns\"\"\"\n",
    "\n",
    "        self.features = df.copy()\n",
    "        self.config = config.copy()\n",
    "\n",
    "        self.OPEN = self.features['OPEN']\n",
    "        self.CLOSE = self.features['CLOSE']\n",
    "        self.HIGH = self.features['HIGH']\n",
    "        self.LOW = self.features['LOW']\n",
    "        self.VOLUME = self.features['VOLUME']\n",
    "        self.LOG_RETURN = np.log(self.OPEN / self.OPEN.shift())\n",
    "\n",
    "    def distribution_features(self):\n",
    "        \"\"\"Standard Deviation, Skewness, and Kurtosis\"\"\"\n",
    "\n",
    "        for w in self.config['DISTRIBUTION']:\n",
    "            self.features[f'STD_{w}'] = self.LOG_RETURN.rolling(w).std()\n",
    "            self.features[f'SKEW_{w}'] = self.LOG_RETURN.rolling(w).skew()\n",
    "            self.features[f'KURT_{w}'] = self.LOG_RETURN.rolling(w).kurt()\n",
    "\n",
    "    def momentum_features(self):\n",
    "        \"\"\"Directional & Oscillator Features\"\"\"\n",
    "\n",
    "        # LOG RETURN\n",
    "        self.features['LOG_RETURN'] = self.LOG_RETURN\n",
    "\n",
    "        # RATE OF CHANGE\n",
    "        for w in self.config['MOMENTUM']['ROC']:\n",
    "            self.features[f'ROC_{w}'] = ((self.OPEN - self.OPEN.shift(w)) / self.OPEN.shift(w)) * 100\n",
    "\n",
    "        # MOVING AVERAGES\n",
    "        for w in self.config['MOMENTUM']['MA']:\n",
    "            self.features[f\"SMA_{w}\"] = self.OPEN.rolling(w).mean()\n",
    "            self.features[f\"EWMA_{w}\"] = self.OPEN.ewm(w, adjust=False).mean()\n",
    "\n",
    "        # RELATIVE STRENGH INDEX (RSI)\n",
    "        delta = self.OPEN.diff()\n",
    "        for w in self.config['MOMENTUM']['RSI']:\n",
    "            gain = (delta.where(delta > 0, 0)).rolling(w).mean()\n",
    "            loss = (-delta.where(delta < 0, 0)).rolling(w).mean()\n",
    "            self.features[f\"RSI_{w}\"] = 100 - (100 / (1 + gain / (loss + 1e-9)))\n",
    "\n",
    "        # MACD & MACD SPREAD\n",
    "        for w in self.config['MOMENTUM']['MACD']:\n",
    "            short_ewma = self.OPEN.ewm(w[0], adjust=False).mean()\n",
    "            long_ewma = self.OPEN.ewm(w[1], adjust=False).mean()\n",
    "            self.features[f\"MACD_{w[0]}_{w[1]}\"] = short_ewma - long_ewma\n",
    "            macd = self.features[f\"MACD_{w[0]}_{w[1]}\"]\n",
    "            macd_signal = macd.ewm(9, adjust=False).mean()\n",
    "            self.features[f\"MACD_SPREAD_{w[0]}_{w[1]}\"] = macd - macd_signal\n",
    "\n",
    "        # STOCHASTIC OSCILATOR\n",
    "        for w in self.config['MOMENTUM']['STOCH']:\n",
    "            low_min = self.LOW.rolling(w).min()\n",
    "            high_max = self.HIGH.rolling(w).max()\n",
    "            self.features[f'STOCH_{w}'] = 100 * (self.OPEN - low_min) / (high_max - low_min)\n",
    "\n",
    "        # TRIPLE EWMA (TEWMA)\n",
    "        for w in self.config['MOMENTUM']['TEWMA']:\n",
    "            ema1 = self.OPEN.ewm(w, adjust=False).mean()\n",
    "            ema2 = ema1.ewm(w, adjust=False).mean()\n",
    "            ema3 = ema2.ewm(w, adjust=False).mean()\n",
    "            self.features[f\"TEWMA_{w}\"] = 3 * ema1 - 3 * ema2 + ema3\n",
    "\n",
    "    def volatility_features(self):\n",
    "        \"\"\"Dispersion Features\"\"\"\n",
    "\n",
    "        # AVERAGE TRUE RANGE (ATR)\n",
    "        for w in self.config['VOLATILITY']['ATR']:\n",
    "            high_low = self.HIGH - self.LOW\n",
    "            high_close = np.abs(self.HIGH - self.CLOSE.shift())\n",
    "            low_close = np.abs(self.LOW - self.CLOSE.shift())\n",
    "            true_range = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)\n",
    "            self.features[f\"ATR_{w}\"] = true_range.rolling(w).mean()\n",
    "\n",
    "        # PARKINSON VOLATILITY (PARK)\n",
    "        for w in self.config['VOLATILITY']['PARK']:\n",
    "            self.features[f\"PARK_VOL_{w}\"] = np.sqrt((1 / (4 * np.log(2))) *\n",
    "                                                     (np.log(self.HIGH / self.LOW) ** 2)\n",
    "                                                     .rolling(w).mean())\n",
    "\n",
    "        # BOLLINGER BANDS (BB)\n",
    "        for w in self.config['VOLATILITY']['BB']:\n",
    "            sma = self.OPEN.rolling(w).mean()\n",
    "            std = self.OPEN.rolling(w).std()\n",
    "            upper, lower = sma + 2 * std, sma - 2 * std\n",
    "            self.features[f\"BB_WIDTH_{w}\"] = upper - lower\n",
    "            self.features[f\"BB_POS_{w}\"] = (self.OPEN - lower) / ((upper - lower) + 1e-9)\n",
    "\n",
    "    def liquidity_features(self):\n",
    "        \"\"\"Volume-driven Features\"\"\"\n",
    "\n",
    "        # VOLUME MA & RATIO\n",
    "        for w in self.config['LIQUIDITY']['MA']:\n",
    "            volume_sma = self.VOLUME.rolling(w).mean()\n",
    "            self.features[f'VOLUME_SMA_{w}'] = volume_sma\n",
    "            self.features[f'VOLUME_RATIO_{w}'] = self.VOLUME / volume_sma\n",
    "\n",
    "        # ON-BALANCE VOLUME (OBV)\n",
    "        self.features['OBV'] = (np.sign(self.features['LOG_RETURN']) * self.VOLUME).cumsum()\n",
    "\n",
    "        # MONEY FLOW RATIO (MFR)\n",
    "        avg_price = (self.HIGH + self.LOW + self.CLOSE) / 3\n",
    "        money_flow = avg_price * self.VOLUME\n",
    "        for w in self.config['LIQUIDITY']['MFR']:\n",
    "            mf_mean = money_flow.rolling(w).mean()\n",
    "            self.features[f'MF_RATIO_{w}'] = money_flow / mf_mean\n",
    "\n",
    "    def microstructure_features(self):\n",
    "        \"\"\"Candle geometry and order flow imbalance\"\"\"\n",
    "\n",
    "        candle_range = self.HIGH - self.LOW\n",
    "        body_size = abs(self.CLOSE - self.OPEN)\n",
    "        upper_body = self.features[['OPEN', 'CLOSE']].max(axis=1)\n",
    "        lower_body = self.features[['OPEN', 'CLOSE']].min(axis=1)\n",
    "\n",
    "        close_low = self.CLOSE - self.LOW\n",
    "        high_close = self.HIGH - self.CLOSE\n",
    "        close_open = self.CLOSE - self.OPEN\n",
    "\n",
    "        # CANDLE FEATURES\n",
    "        self.features['CANDLE_RANGE'] = candle_range / self.CLOSE\n",
    "        self.features['BODY_SIZE'] = body_size / self.CLOSE\n",
    "        self.features['UPPER_SHADOW'] = (self.HIGH - upper_body) / self.CLOSE\n",
    "        self.features['LOWER_SHADOW'] = (lower_body - self.LOW) / self.CLOSE\n",
    "\n",
    "        # BUY/SELL PRESSURE\n",
    "        self.features['BUY_PRESSURE'] = np.clip((close_low) / (candle_range + 1e-9), 0, 1) * 100\n",
    "        self.features['SELL_PRESSURE'] = np.clip((high_close) / (candle_range + 1e-9), 0, 1) * 100\n",
    "        self.features['TREND_STRENGTH'] = (close_open) / (candle_range + 1e-9) * 100\n",
    "\n",
    "    def temporal_features(self):\n",
    "        \"\"\"Cyclical time encodings to capture seasonality\"\"\"\n",
    "\n",
    "        self.features['HOUR_SIN'] = np.sin(2 * np.pi * self.features.index.hour / 24)\n",
    "        self.features['HOUR_COS'] = np.cos(2 * np.pi * self.features.index.hour / 24)\n",
    "        self.features['MINUTE_SIN'] = np.sin(2 * np.pi * self.features.index.minute / 60)\n",
    "        self.features['MINUTE_COS'] = np.cos(2 * np.pi * self.features.index.minute / 60)\n",
    "        self.features['WEEKDAY_SIN'] = np.sin(2 * np.pi * self.features.index.dayofweek / 7)\n",
    "\n",
    "    def handle_na(self, threshold=0.05):\n",
    "        \"\"\"Compute NaN ratio and drop NaN values\"\"\"\n",
    "\n",
    "        na_ratio = self.features.isna().sum().sum() / (self.features.shape[0] * self.features.shape[1])\n",
    "        print(f\"Missing Value Ratio: {na_ratio:.2%}\")\n",
    "\n",
    "        if na_ratio < threshold:\n",
    "            self.features.dropna(inplace=True)\n",
    "            print(\"NaN values dropped.\")\n",
    "        else:\n",
    "            print(\"Consider imputation: NaN ratio above threshold.\")\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Run all methods\"\"\"\n",
    "\n",
    "        self.distribution_features()\n",
    "        self.momentum_features()\n",
    "        self.volatility_features()\n",
    "        self.liquidity_features()\n",
    "        self.microstructure_features()\n",
    "        self.temporal_features()\n",
    "        self.handle_na()\n",
    "\n",
    "        return self.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc8db6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up config dictionary for Features Builder\n",
    "config = {\n",
    "    'MOMENTUM': {\n",
    "        'ROC': [5, 10, 20, 60],\n",
    "        'RSI': [14, 21, 28],\n",
    "        'MACD': [(6, 12), (12, 24)],\n",
    "        'STOCH': [10, 30, 60],\n",
    "        'MA': [5, 10, 20, 50],\n",
    "        'TEWMA': [20, 40]\n",
    "    },\n",
    "\n",
    "    'VOLATILITY': {\n",
    "        'ATR': [14, 28, 60],\n",
    "        'BB': [10, 20],\n",
    "        'PARK': [30, 60]\n",
    "    },\n",
    "\n",
    "    'LIQUIDITY': {\n",
    "        'MA': [10, 20, 50],\n",
    "        'MFR': [5, 10, 20]\n",
    "    },\n",
    "\n",
    "    'DISTRIBUTION': [10, 50, 100, 150]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0416b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build features\n",
    "builder = FeatureBuilder(df, config)\n",
    "features_df = builder.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65434e7a",
   "metadata": {},
   "source": [
    "# Features Preprocessor Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adffd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeaturePreprocessor:\n",
    "\n",
    "    def __init__(self, features_df, target='OPEN', shift=2):\n",
    "        \"\"\"Fetch dataframe, target, and shift\"\"\"\n",
    "\n",
    "        self.features = features_df.copy()\n",
    "        self.target = target\n",
    "        self.shift = shift\n",
    "\n",
    "    def split_X_y(self):\n",
    "        \"\"\"Split features X and target y\"\"\"\n",
    "\n",
    "        # Shift target such that y(t) = Open(t+shift)\n",
    "        y = self.features[[self.target]].shift(-self.shift)\n",
    "\n",
    "        # Store X and y, avoiding forward-looking bias\n",
    "        X = self.features.drop(self.target, axis=1)\n",
    "        X, y = X.align(y, join='inner', axis=0)\n",
    "        self.X = X.dropna()\n",
    "        self.y = y.loc[self.X.index]\n",
    "\n",
    "    def standardize_X(self):\n",
    "        \"\"\"Standardize features X to zero mean and variance\"\"\"\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        scaled_X = scaler.fit_transform(self.X)\n",
    "        self.standard_X = pd.DataFrame(scaled_X, columns=self.X.columns, index=self.X.index)\n",
    "\n",
    "    def plot_standard_X(self):\n",
    "        \"\"\"Plot standardized features\"\"\"\n",
    "\n",
    "        features = self.standard_X.columns\n",
    "        n_features = len(features)\n",
    "\n",
    "        n_cols = int(np.ceil(np.sqrt(n_features))) + 3\n",
    "        n_rows = int(np.ceil(n_features / n_cols))\n",
    "        fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 8))\n",
    "        axes = axes.flatten()\n",
    "\n",
    "        # Plot histogram for each feature\n",
    "        for i, col in enumerate(features):\n",
    "            sns.histplot(self.standard_X[col], kde=True, stat='percent', ax=axes[i], bins=20)\n",
    "            axes[i].set_title(f\"{col}\", fontsize=10)\n",
    "            axes[i].set_xlabel(\"\")\n",
    "            axes[i].set_ylabel(\"\")\n",
    "            axes[i].axvline(0, color='red', linestyle='-', linewidth=1)\n",
    "\n",
    "        for j in range(i + 1, len(axes)):\n",
    "            fig.delaxes(axes[j])\n",
    "\n",
    "        fig.suptitle(\"Standardized Features Distributions\",\n",
    "                     fontsize=16, fontweight='bold', y=1)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Run all methods\"\"\"\n",
    "\n",
    "        self.split_X_y()\n",
    "        self.standardize_X()\n",
    "        self.plot_standard_X()\n",
    "\n",
    "        return self.standard_X, self.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587ab6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess features\n",
    "preprocessor = FeaturePreprocessor(features_df)\n",
    "X, y = preprocessor.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba690692",
   "metadata": {},
   "source": [
    "# PCA Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80861bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrincipalComponent:\n",
    "\n",
    "    def __init__(self, X, n_components=None):\n",
    "        \"\"\"Fetch X and n_components\"\"\"\n",
    "\n",
    "        self.X = X\n",
    "        self.n_components = n_components\n",
    "\n",
    "    def perform_pca(self):\n",
    "        \"\"\"Run PCA and store attributes\"\"\"\n",
    "\n",
    "        if self.n_components is None:\n",
    "            self.n_components = min(self.X.shape[0], self.X.shape[1])\n",
    "\n",
    "        # Instantiate model, fit and transform X\n",
    "        self.pca_model = PCA(n_components=self.n_components)\n",
    "        components = self.pca_model.fit_transform(self.X)\n",
    "\n",
    "        # Store eigenvalues\n",
    "        self.explained_variance = self.pca_model.explained_variance_\n",
    "        self.explained_variance_ratio = self.pca_model.explained_variance_ratio_\n",
    "        self.cumulative_variance_ratio = np.cumsum(self.explained_variance_ratio)\n",
    "\n",
    "        # Store loadings\n",
    "        loadings = self.pca_model.components_.T * np.sqrt(self.explained_variance)\n",
    "        components_cols = [f'PC{i+1}' for i in range(components.shape[1])]\n",
    "        self.loadings_df = pd.DataFrame(loadings, index=self.X.columns, columns=components_cols)\n",
    "\n",
    "        # Store top-contributing features per component\n",
    "        self.top_features = {}\n",
    "        for component in self.loadings_df.columns[:3]:\n",
    "            top_5 = self.loadings_df[component].abs().sort_values(ascending=False).head(5)\n",
    "            self.top_features[component] = top_5.index.tolist()\n",
    "\n",
    "        # Store scores\n",
    "        self.components_df = pd.DataFrame(components, columns=components_cols, index=self.X.index)\n",
    "\n",
    "        # Send validation message\n",
    "        print('PCA: Done.')\n",
    "\n",
    "    def plot_eigenvalues(self):\n",
    "        \"\"\"Generate scree plot and cumulative variance explaiend plot\"\"\"\n",
    "\n",
    "        # Scree plot\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,5))\n",
    "        n_show = min(50, len(self.explained_variance))\n",
    "\n",
    "        ax1.plot(range(1, n_show+1), self.explained_variance[:n_show], 'bo-', linewidth=2, markersize=6)\n",
    "        ax1.axhline(y=1, color='red', linestyle='--', label='Kaiser Criterion (Î»=1)')\n",
    "        ax1.set_xlabel('Principal Component')\n",
    "        ax1.set_ylabel('Eigenvalue')\n",
    "        ax1.set_title('Scree Plot: Eigenvalue by Principal Component', weight='bold')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        ax1.legend()\n",
    "\n",
    "        # Cumulative variance explained plot\n",
    "        ax2.plot(range(1, n_show+1), self.cumulative_variance_ratio[:n_show]*100,\n",
    "                 'go-', linewidth=2, markersize=6)\n",
    "        ax2.axhline(y=80, color='orange', linestyle='--', label='80% Variance')\n",
    "        ax2.axhline(y=90, color='red', linestyle='--', label='90% Variance')\n",
    "        ax2.set_xlabel('Number of Components')\n",
    "        ax2.set_ylabel('Cumulative Variance Explained (%)')\n",
    "        ax2.set_title('Cumulative Variance Explained by Principal Components', weight='bold')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        ax2.legend()\n",
    "\n",
    "        plt.suptitle(\"Scree Plots: Eigenvalues Distribution\", fontsize=12, fontweight='bold', y=0.99)\n",
    "        plt.tight_layout()\n",
    "\n",
    "    def plot_loadings_2D(self):\n",
    "        \"\"\"Generate loading plots for all component pairs\"\"\"\n",
    "\n",
    "        fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "        # Plot each pair using helper method _plot_loading_pair\n",
    "        self.colors_dic = {'PC1': 'steelblue', 'PC2': 'darkorange', 'PC3': 'seagreen'}\n",
    "        self._plot_loading_pair(ax1, 'PC1', 'PC2')\n",
    "        self._plot_loading_pair(ax2, 'PC1', 'PC3')\n",
    "        self._plot_loading_pair(ax3, 'PC2', 'PC3')\n",
    "\n",
    "        # Formatting\n",
    "        handles, labels = ax1.get_legend_handles_labels()\n",
    "        ax1.legend(handles, labels, loc='upper left', fontsize=10, frameon=True)\n",
    "        ax2.legend(handles, labels, loc='upper right', fontsize=10, frameon=True)\n",
    "        ax3.legend(handles, labels, loc='upper right', fontsize=10, frameon=True)\n",
    "        plt.suptitle(\"Loading Plots (2D)\", fontsize=14, fontweight='bold', y=0.98)\n",
    "        plt.tight_layout()\n",
    "\n",
    "    def _plot_loading_pair(self, ax, component_x, component_y):\n",
    "        \"\"\"Helper: Generate loading plot for component_x and component_y\"\"\"\n",
    "\n",
    "        # Plot top-contributing features\n",
    "        for component, color in self.colors_dic.items():\n",
    "\n",
    "            # Scatter points\n",
    "            top_features = self.top_features.get(component, [])\n",
    "            top_loadings = self.loadings_df.loc[top_features, [component_x, component_y]].values\n",
    "            ax.scatter(top_loadings[:, 0], top_loadings[:, 1], color=color,\n",
    "                       s=60, label=f'Top 5 {component}', edgecolor='black')\n",
    "\n",
    "            # Generate cluster circles\n",
    "            x_center, y_center = top_loadings.mean(axis=0)\n",
    "            radius = np.max(np.linalg.norm(top_loadings - [x_center, y_center], axis=1)) + 0.03\n",
    "            circle = plt.Circle((x_center, y_center), radius, color=color, fill=False,\n",
    "                                linewidth=1.8, linestyle='--', alpha=0.8)\n",
    "            ax.add_patch(circle)\n",
    "\n",
    "        # Plot remaining features\n",
    "        ax.scatter(self.loadings_df[component_x], self.loadings_df[component_y],\n",
    "                   color='grey', s=30, alpha=0.4, label='Remaining Features',\n",
    "                   edgecolor='black')\n",
    "\n",
    "        ax.axhline(y=0, color='black', linewidth=1)\n",
    "        ax.axvline(x=0, color='black', linewidth=1)\n",
    "        ax.set_xlabel(f'{component_x} Loadings', fontsize=10)\n",
    "        ax.set_ylabel(f'{component_y} Loadings', fontsize=10)\n",
    "        ax.set_title(f'{component_x} vs {component_y}', fontsize=11, fontweight='bold')\n",
    "        ax.grid(alpha=0.3)\n",
    "\n",
    "    def plot_loadings_summary(self):\n",
    "        \"\"\"Generate 3D loading plot and cross-component analysis\"\"\"\n",
    "\n",
    "        fig = plt.figure(figsize=(15, 4))\n",
    "        gs = gridspec.GridSpec(1, 2, width_ratios=[1.2, 1], wspace=0.25)\n",
    "\n",
    "        # Generate 2D cross-component loadings using helper _plot_cross_component\n",
    "        ax2d = fig.add_subplot(gs[0, 0])\n",
    "        self._plot_cross_component(ax2d)\n",
    "\n",
    "        # Generate 3D loadings plot using helper _plot_loadings_3D\n",
    "        ax3d = fig.add_subplot(gs[0, 1], projection='3d')\n",
    "        ax3d.view_init(25, 35)\n",
    "        self._plot_loadings_3D(ax3d)\n",
    "\n",
    "    def _plot_loadings_3D(self, ax):\n",
    "        \"\"\"Helper: Generate 3D loading plot\"\"\"\n",
    "\n",
    "        components = ['PC1', 'PC2', 'PC3']\n",
    "        loadings = self.loadings_df[components]\n",
    "        norms = np.linalg.norm(loadings.values, axis=1)\n",
    "\n",
    "        # Scatter all points\n",
    "        ax.scatter(loadings['PC1'], loadings['PC2'], loadings['PC3'], c=norms,\n",
    "                   cmap='viridis', s=40, alpha=0.8, edgecolor='k', linewidth=0.8)\n",
    "\n",
    "        # Plot formatting\n",
    "        ax.set_xlabel('PC1 Loadings', labelpad=8, fontsize=9)\n",
    "        ax.set_ylabel('PC2 Loadings', labelpad=8, fontsize=9)\n",
    "        ax.set_zlabel('PC3 Loadings', labelpad=6, fontsize=9)\n",
    "        ax.zaxis.set_rotate_label(False)\n",
    "        ax.zaxis.label.set_rotation(92)\n",
    "        ax.set_title('PCA Loadings in 3D Eigenspace',\n",
    "                     fontsize=10, fontweight='bold', y=0.98)\n",
    "\n",
    "        # Generate color bar for Euclidian distance\n",
    "        sm = plt.cm.ScalarMappable(cmap='viridis')\n",
    "        sm.set_array(norms)\n",
    "        plt.colorbar(sm, ax=ax, shrink=0.5, alpha= 0.7, aspect=20,\n",
    "                     pad=0.03, label='Euclidian Distance')\n",
    "\n",
    "    def _plot_cross_component(self, ax):\n",
    "        \"\"\"Helper: Generate cross-component loading analysis for top 5 features per PC.\"\"\"\n",
    "\n",
    "        components = list(self.top_features.keys())[:3]\n",
    "        colors = self.colors_dic\n",
    "        feature_groups = [self.top_features[c] for c in components]\n",
    "        x_labels = sum(feature_groups, [])\n",
    "        x_positions = np.arange(len(x_labels))\n",
    "\n",
    "        # Plot loadings for each component\n",
    "        for comp in components:\n",
    "            y = self.loadings_df.loc[x_labels, comp]\n",
    "            ax.plot(x_positions, y, 'o-', color=colors[comp],\n",
    "                    label=comp, linewidth=2, markersize=5)\n",
    "\n",
    "        # Shade regions for each feature group\n",
    "        seg_w = len(feature_groups[0])\n",
    "        for i, comp in enumerate(components):\n",
    "            start, end = i * seg_w, (i + 1) * seg_w\n",
    "            ax.axvspan(start - 0.5, end - 0.5, color=colors[comp], alpha=0.08)\n",
    "            ax.text((start + end - 1) / 2, ax.get_ylim()[1] * 0.9, comp,\n",
    "                    ha='center', va='top', color=colors[comp],\n",
    "                    fontweight='bold', alpha=0.8)\n",
    "\n",
    "        # Formatting\n",
    "        ax.set_xticks(x_positions)\n",
    "        ax.set_xticklabels(x_labels, rotation=45, ha='right', fontsize=9)\n",
    "        ax.axhline(0, color='k', linewidth=1)\n",
    "        ax.set_title(\"Cross-Component Loadings on Top 5 Features per PC\", fontsize=12, fontweight='bold')\n",
    "        ax.set_ylabel(\"Feature Loadings\", fontsize=10)\n",
    "        ax.set_xlabel(\"Top Features by Principal Component\", fontsize=10)\n",
    "        ax.legend(title=\"Principal Components\", frameon=True, fontsize=9)\n",
    "        ax.grid(alpha=0.3)\n",
    "\n",
    "    def plot_scores(self):\n",
    "        \"\"\"Generate score plots for all component pairs\"\"\"\n",
    "\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "        pairs = [('PC1', 'PC2'), ('PC1', 'PC3'), ('PC2', 'PC3')]\n",
    "\n",
    "        for ax, (x_pc, y_pc) in zip(axes, pairs):\n",
    "            data_pair = self.components_df[[x_pc, y_pc]].values\n",
    "            mean = data_pair.mean(axis=0)\n",
    "            cov = np.cov(data_pair, rowvar=False)\n",
    "            cov_inv = np.linalg.inv(cov)\n",
    "\n",
    "            # Compute Mahalanobis distance\n",
    "            mahal_distances = np.array([mahalanobis(point, mean, cov_inv) for point in data_pair])\n",
    "\n",
    "            # Scatter points colored by Mahalanobis distance\n",
    "            scatter = ax.scatter(\n",
    "                self.components_df[x_pc], self.components_df[y_pc],\n",
    "                c=mahal_distances, cmap='viridis', s=20, alpha=0.8)\n",
    "\n",
    "            # Formatting\n",
    "            ax.set_xlabel(f\"{x_pc} Score\", fontsize=11)\n",
    "            ax.set_ylabel(f\"{y_pc} Score\", fontsize=11)\n",
    "            ax.set_title(f\"{x_pc} vs {y_pc}\", fontsize=12, fontweight='normal')\n",
    "            ax.grid(alpha=0.3)\n",
    "\n",
    "            # Generate color bar\n",
    "            cbar = fig.colorbar(scatter, ax=ax, pad=0.02)\n",
    "            cbar.set_label('Mahalanobis Distance', fontsize=11)\n",
    "            cbar.solids.set_alpha(0.8)\n",
    "\n",
    "        fig.suptitle('Score Plots', fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a35958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "pca_model = PrincipalComponent(X)\n",
    "pca_model.perform_pca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c0f3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot eigenvalues\n",
    "pca_model.plot_eigenvalues()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51a133b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Loadings\n",
    "pca_model.plot_loadings_2D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab078070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Loadings Summary\n",
    "pca_model.plot_loadings_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045b4faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot scores \n",
    "pca_model.plot_scores()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
